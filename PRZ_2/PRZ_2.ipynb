{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практическая работа №2\n",
        "Выполнил Шмарковский МБ ББМО-02-22\n",
        "\n",
        "## Ход работы"
      ],
      "metadata": {
        "id": "tCOx62K-bDOg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zqzI-mWnZ1tQ",
        "outputId": "a48bf98b-9f2a-48ec-c79a-ab16d8518d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEL6812_DeepFool_Project'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 96 (delta 2), reused 1 (delta 1), pack-reused 93\u001b[K\n",
            "Receiving objects: 100% (96/96), 33.99 MiB | 8.06 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ],
      "source": [
        "# Скопируем проект по ссылке в локальную среду выполнения Jupyter (Google Colab)\n",
        "!git clone https://github.com/ewatson2/EEL6812_DeepFool_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сменим директорию исполнения на вновь созданную папку \"EEL6812_DeepFool_Project\"проекта.\n",
        "%cd /content/EEL6812_DeepFool_Project"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Z0FYBl-zaDHA",
        "outputId": "983a162a-7263-4e02-ec84-9aa5eecde631"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EEL6812_DeepFool_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Выполним импорт необходимых библиотек\n",
        "import numpy as np\n",
        "import json, torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision  import datasets, models\n",
        "from torchvision.transforms import transforms"
      ],
      "metadata": {
        "id": "R8Cr9IcValDq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Выполним импорт вспомогательных библиотек из локальных файлов проекта\n",
        "from models.project_models import FC_500_150, LeNet_CIFAR, LeNet_MNIST, Net\n",
        "from utils.project_utils import get_clip_bounds, evaluate_attack, display_attack"
      ],
      "metadata": {
        "id": "XaKh4XhubCL6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Установим случайное рандомное значение в виде переменной rand_seed={\"Порядковый номер ученика группы в Гугл-таблице\"}, укажем значение для np.random.seed и torch.manual_seed\n",
        "rand_seed = 8\n",
        "np.random.seed(rand_seed)\n",
        "torch.manual_seed(rand_seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SLY9dF1PcDba",
        "outputId": "5d4c3a8d-6769-4ad0-a13c-3d34f6dc7092"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4eb34ee5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Используем в качестсве устройства видеокарту\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')"
      ],
      "metadata": {
        "id": "zz3wwUDscYP2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузим датасет MNIST c параметрами mnist_mean = 0.5, mnist_std = 0.5, mnist_dim = 28\n",
        "mnist_mean = 0.5\n",
        "mnist_std = 0.5\n",
        "mnist_dim = 28\n",
        "\n",
        "mnist_min, mnist_max = get_clip_bounds(mnist_mean, mnist_std, mnist_dim)\n",
        "\n",
        "mnist_min = mnist_min.to(device)\n",
        "mnist_max = mnist_max.to(device)\n",
        "\n",
        "mnist_tf = transforms.Compose([ transforms.ToTensor(), transforms.Normalize( mean=mnist_mean, std=mnist_std)])\n",
        "\n",
        "mnist_tf_train = transforms.Compose([ transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize( mean=mnist_mean, std=mnist_std)])\n",
        "\n",
        "mnist_tf_inv = transforms.Compose([ transforms.Normalize( mean=0.0, std=np.divide(1.0, mnist_std)), transforms.Normalize( mean=np.multiply(-1.0, mnist_std), std=1.0)])\n",
        "\n",
        "mnist_temp = datasets.MNIST(root='datasets/mnist', train=True, download=True, transform=mnist_tf_train)\n",
        "mnist_train, mnist_val = random_split(mnist_temp, [50000, 10000])\n",
        "mnist_test = datasets.MNIST(root='datasets/mnist', train=False, download=True, transform=mnist_tf)"
      ],
      "metadata": {
        "id": "1yj-Xs6LdM-p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузим датасет CIFAR-10 c параметрами cifar_mean = [0.491, 0.482, 0.447] cifar_std = [0.202, 0.199, 0.201] cifar_dim = 32\n",
        "cifar_mean = [0.491, 0.482, 0.447]\n",
        "cifar_std = [0.202, 0.199, 0.201]\n",
        "cifar_dim = 32\n",
        "\n",
        "cifar_min, cifar_max = get_clip_bounds(cifar_mean, cifar_std, cifar_dim)\n",
        "\n",
        "cifar_min = cifar_min.to(device)\n",
        "cifar_max = cifar_max.to(device)\n",
        "\n",
        "cifar_tf = transforms.Compose([ transforms.ToTensor(), transforms.Normalize( mean=cifar_mean, std=cifar_std)])\n",
        "\n",
        "cifar_tf_train = transforms.Compose([ transforms.RandomCrop( size=cifar_dim, padding=4), transforms.RandomHorizontalFlip(), transforms.ToTensor(), transforms.Normalize( mean=cifar_mean, std=cifar_std)])\n",
        "\n",
        "cifar_tf_inv = transforms.Compose([ transforms.Normalize( mean=[0.0, 0.0, 0.0], std=np.divide(1.0, cifar_std)), transforms.Normalize( mean=np.multiply(-1.0, cifar_mean), std=[1.0, 1.0, 1.0])])\n",
        "\n",
        "cifar_temp = datasets.CIFAR10(root='datasets/cifar-10', train=True, download=True, transform=cifar_tf_train)\n",
        "\n",
        "cifar_train, cifar_val = random_split(cifar_temp, [40000, 10000])\n",
        "cifar_test = datasets.CIFAR10(root='datasets/cifar-10', train=False, download=True, transform=cifar_tf)\n",
        "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F8PHWqTod5jg",
        "outputId": "699173ce-0615-4af2-a787-afa2d09be60e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Выполним настройку и загрузку DataLoader batch_size = 64 workers = 4\n",
        "batch_size = 64\n",
        "workers = 4\n",
        "\n",
        "mnist_loader_train = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "mnist_loader_val = DataLoader(mnist_val, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "mnist_loader_test = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "\n",
        "cifar_loader_train = DataLoader(cifar_train, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
        "cifar_loader_val = DataLoader(cifar_val, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
        "cifar_loader_test = DataLoader(cifar_test, batch_size=batch_size, shuffle=False, num_workers=workers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "C8NFgcMTe5SS",
        "outputId": "de85da2f-1aee-4afc-bd0d-5ff8efd5c3bb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Инициализируем deep_args\n",
        "batch_size = 10\n",
        "num_classes = 10\n",
        "overshoot = 0.02\n",
        "max_iters = 50\n",
        "deep_args = [batch_size, num_classes, overshoot, max_iters]"
      ],
      "metadata": {
        "id": "MQGt3o0CfuST"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузим и оценим стойкость модели LeNet к FGSM и DeepFool атакам\n",
        "fgsm_eps = 0.6\n",
        "model = LeNet_MNIST().to(device)\n",
        "model.load_state_dict(torch.load('weights/clean/mnist_lenet.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "evaluate_attack('mnist_lenet_fgsm.csv', 'results', device, model, mnist_loader_test, mnist_min, mnist_max, fgsm_eps, is_fgsm=True)\n",
        "print('')\n",
        "evaluate_attack('mnist_lenet_deepfool.csv', 'results', device, model, mnist_loader_test, mnist_min, mnist_max, deep_args, is_fgsm=False)\n",
        "\n",
        "if device.type == 'cuda': torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kLhfylMwfNxD",
        "outputId": "67b78be7-287c-44d3-bf58-f8f87cc3971d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM Test Error : 87.89%\n",
            "FGSM Robustness : 4.58e-01\n",
            "FGSM Time (All Images) : 0.29 s\n",
            "FGSM Time (Per Image) : 28.86 us\n",
            "\n",
            "DeepFool Test Error : 98.74%\n",
            "DeepFool Robustness : 9.64e-02\n",
            "DeepFool Time (All Images) : 193.32 s\n",
            "DeepFool Time (Per Image) : 19.33 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузим и оценим стойкость модели FC к FGSM и DeepFool атакам\n",
        "fgsm_eps = 0.2\n",
        "model = FC_500_150().to(device)\n",
        "model.load_state_dict(torch.load('weights/clean/mnist_fc.pth', map_location=torch.device('cpu')))\n",
        "\n",
        "evaluate_attack('mnist_fc_fgsm.csv', 'results', device, model, mnist_loader_test, mnist_min, mnist_max, fgsm_eps, is_fgsm=True)\n",
        "print('')\n",
        "evaluate_attack('mnist_fc_deepfool.csv', 'results', device, model, mnist_loader_test, mnist_min, mnist_max, deep_args, is_fgsm=False)\n",
        "\n",
        "if device.type == 'cuda': torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NkmSMto5g9w8",
        "outputId": "207cec39-412a-4b16-a96b-6bd21e3963f2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM Test Error : 87.08%\n",
            "FGSM Robustness : 1.56e-01\n",
            "FGSM Time (All Images) : 0.15 s\n",
            "FGSM Time (Per Image) : 14.99 us\n",
            "\n",
            "DeepFool Test Error : 97.92%\n",
            "DeepFool Robustness : 6.78e-02\n",
            "DeepFool Time (All Images) : 141.81 s\n",
            "DeepFool Time (Per Image) : 14.18 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "LeNet проявляет большую устойчивость как к атакам FGSM, так и к атакам DeepFool.\n",
        "FC немного лучше справляется с ошибками тестирования и значительно быстрее обрабатывает как все изображения, так и каждое изображение."
      ],
      "metadata": {
        "id": "I3XKMg-Tis_n"
      }
    }
  ]
}